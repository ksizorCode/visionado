# Apuntes Introductorios de VisiÃ³n por Ordenador
---

## 1. IntroducciÃ³n a la Inteligencia Artificial  

> **Ejemplo cinematogrÃ¡fico**: En *2001: Una odisea del espacio*, HAL 9000 representa una IA â€œgeneralâ€ capaz de razonar y tomar decisiones complejas. Sin embargo, hoy en dÃ­a, la mayorÃ­a de sistemas de IA son â€œnarrowâ€ (estrechos), especializados en tareas concretas.

### 1.1 Â¿QuÃ© es la Inteligencia Artificial?  
- **DefiniciÃ³n bÃ¡sica**: Rama de la informÃ¡tica dedicada a crear sistemas que imitan funciones cognitivas humanas como aprender, razonar, planificar y resolver problemas.  
- **Objetivo prÃ¡ctico**: Automatizar tareas que requieren â€œinteligenciaâ€ (diagnÃ³stico mÃ©dico, reconocimiento de voz, recomendaciÃ³n de contenidos, etc.).  

### 1.2 Tipos de Inteligencia Artificial  
1. **IA DÃ©bil (Narrow AI)**  
   - DiseÃ±ada para UNA tarea especÃ­fica (por ejemplo, Siri o Alexa).  
   - No â€œentiendeâ€ ni razona fuera de su dominio. 
   - Ejemplo: 

2. **IA Fuerte (General AI / AGI)**  
   - Persigue replicar la inteligencia humana en toda su amplitud.  
   - Capaz de aprender, comprender y aplicar conocimientos en mÃºltiples dominios.  
   - **Â¡AÃºn no existe en la prÃ¡ctica!**  

3. **IA SÃºper (Superintelligence)**  
   - HipotÃ©tica. Inteligencia que supera a la humana en todas las tareas cognitivas.  
   - Tema recurrente en la cultura friky (por ejemplo, Skynet en *Terminator*).  

---

## 2. Aprendizaje AutomÃ¡tico (Machine Learning)  

> **Ejemplo videojuego**: En *FIFA*, el comportamiento de los jugadores â€œaprendeâ€ a base de datos gigantes de partidos. No es magia: son algoritmos que identifican patrones en las jugadas.

### 2.1 Â¿QuÃ© es el Machine Learning (ML)?  
- Subcampo de la IA que construye sistemas capaces de **aprender** de datos sin ser explÃ­citamente programados para cada situaciÃ³n.  
- **Idea clave**: Alimentar al modelo con ejemplos (datos de entrenamiento) y dejar que extraiga patrones.

### 2.2 Componentes BÃ¡sicos de un Problema de ML  
1. **Datos de entrada (features)**: Variables que describen cada caso (e.g., pÃ­xeles de una imagen, caracterÃ­sticas de audio).  
2. **Etiqueta o target**: Lo que queremos predecir (e.g., â€œgatoâ€ vs â€œperroâ€, precio de una casa).  
3. **Modelo**: Conjunto de parÃ¡metros que relacionan entradas y salidas (por ejemplo, los coeficientes de una regresiÃ³n).  
4. **FunciÃ³n de pÃ©rdida (loss)**: Mide cuÃ¡n lejos estÃ¡ la predicciÃ³n del valor real.  
5. **Algoritmo de optimizaciÃ³n**: Ajusta los parÃ¡metros minimizando la funciÃ³n de pÃ©rdida (e.g., gradiente descendente).

### 2.3 Tipos de Aprendizaje AutomÃ¡tico  
1. **Aprendizaje Supervisado**  
   - Datos etiquetados: cada ejemplo incluye la respuesta correcta.  
   - **Tareas**:  
     - **RegresiÃ³n**: Predecir valores continuos (p. ej., precio de la vivienda, temperatura).  
     - **ClasificaciÃ³n**: Asignar etiquetas discretas (p. ej., gato vs perro).  
   - **Modelos comunes**:  
     - RegresiÃ³n Lineal / LogÃ­stica  
     - Support Vector Machines (SVM)  
     - Ãrboles de DecisiÃ³n y Random Forest  
     - K-Nearest Neighbors (KNN)  

2. **Aprendizaje No Supervisado**  
   - Datos sin etiquetas. El objetivo es **descubrir estructuras** ocultas.  
   - **Tareas**:  
     - **Clustering (agrupamiento)**: k-means, DBSCAN (ejemplo: agrupar pÃ­xeles similares en una imagen).  
     - **ReducciÃ³n de dimensionalidad**: PCA, t-SNE (Ãºtil para visualizaciÃ³n de datos complejos).  
   - **Ejemplo friki**: En *Matrix*, los â€œagentesâ€ podrÃ­an representar clusters de pÃ­xeles que definen a Neo; cada vez que Neo aparece, los pÃ­xeles se agrupan en torno a Ã©l.  

3. **Aprendizaje por Refuerzo**  
   - Agente aprende a tomar decisiones interactuando con un entorno y recibiendo **recompensas** o **penalizaciones**.  
   - En visiÃ³n por ordenador, se usa menos frecuentemente, pero puede aplicarse para tareas como **robot vision** donde un robot ajusta su cÃ¡mara para mejorar la percepciÃ³n.

---

## 3. Deep Learning  

> **Ejemplo cine**: En *Ex Machina*, la IA Ava utiliza redes neuronales (hipotÃ©ticas) para interpretar lenguaje y reconocer rostros en tiempo real. Nuestras CNN actuales son un â€œprimo lejanoâ€ de esa idea.

### 3.1 Â¿QuÃ© es Deep Learning (DL)?  
- Subcampo del ML basado en **Redes Neuronales Artificiales** (ANN) profundas (mÃºltiples capas ocultas).  
- **Inspirado en la estructura del cerebro**, aunque con simplificaciones enormes.  
- Especialmente poderoso en tareas de visiÃ³n, audio y lenguaje natural.

### 3.2 Redes Neuronales Convolucionales (CNN)  
#### 3.2.1 Concepto y Estructura  
- DiseÃ±adas para procesar datos con **estructura de cuadrÃ­cula** (por ejemplo, imÃ¡genes).  
- Componentes bÃ¡sicos:  
  1. **Capas Convolucionales**: Filtros (kernels) que â€œdeslizanâ€ sobre la imagen para detectar **patrones locales** (bordes, texturas).  
  2. **OperaciÃ³n de Pooling**: Reduce la resoluciÃ³n espacial (downsampling), capturando informaciÃ³n relevante con menos datos (max-pooling, average-pooling).  
  3. **Capas Completamente Conectadas (fully connected)**: Al final de la red, para combinar caracterÃ­sticas extraÃ­das y producir una predicciÃ³n global.  

#### 3.2.2 CaracterÃ­sticas de las CNN  
- **Invariancia a Traslaciones**: Un filtro que detecta un borde horizontal lo harÃ¡ en cualquier parte de la imagen.  
- **ParÃ¡metros Compartidos**: Un mismo kernel se aplica en toda la imagen, lo que reduce drÃ¡sticamente la cantidad de parÃ¡metros.  
- **JerarquÃ­a de CaracterÃ­sticas**:  
  - Capas bajas â†’ detectan bordes y texturas simples (e.g., detectores de bordes como Sobel).  
  - Capas intermedias â†’ detectan formas (ojos, ruedas, ventanas).  
  - Capas altas â†’ detectan objetos completos (caras, coches, seÃ±ales de trÃ¡fico).

#### 3.2.3 Â¿CÃ³mo Trabaja una CNN en VisiÃ³n por Ordenador?  
1. **Entrada**: Una imagen (por ejemplo, un fotograma de *Blade Runner*).  
2. **ConvoluciÃ³n + ReLU**: Filtrar la imagen con mÃºltiples kernels, aplicando una funciÃ³n de activaciÃ³n (ReLU) para introducir no linealidad.  
3. **Pooling**: Reducir la dimensiÃ³n espacial (e.g., pasar de 256Ã—256 a 128Ã—128).  
4. **Repetir**: Varias capas de convoluciÃ³n + pooling van extrayendo caracterÃ­sticas cada vez mÃ¡s complejas.  
5. **Capas Fully Connected**: Finalmente, todas las caracterÃ­sticas se â€œaplananâ€ y se procesan para clasificar (o para alguna otra tarea, como regresiÃ³n de bounding boxes).  

> **AnalogÃ­a cinematogrÃ¡fica**: Imagina que cada fotograma de *The Matrix* es pasado por â€œfiltros mÃ¡gicosâ€ que, capa a capa, descubren si ese fotograma corresponde a un agente, a Neo o a un obstÃ¡culo.  

---

## 4. Tipos de Inteligencia Artificial SegÃºn su CapacitaciÃ³n (otra clasificaciÃ³n)  

1. **Sistemas Basados en Reglas (Expert Systems)**  
   - IA clÃ¡sica: â€œSi-entoncesâ€ â†’ e.g., sistemas de diagnÃ³stico mÃ©dicos antiguos.  
   - Limitados al conocimiento incluido manualmente.  

2. **IA EstadÃ­stica (Data-Driven)**  
   - Incluye ML y DL.  
   - Aprende de datos masivos, no de reglas explÃ­citas.  

3. **IA HÃ­brida**  
   - CombinaciÃ³n de enfoques simbÃ³licos (reglas) y subsimbÃ³licos (redes neuronales).  
   - En visiÃ³n por ordenador, a veces se integran mÃ³dulos de inferencia lÃ³gica con CNN para razonamiento.

---

## 5. VisiÃ³n por Ordenador (Computer Vision)  

> **Ejemplo friki**: En *Minority Report*, la policÃ­a analiza imÃ¡genes en tiempo real para predecir crÃ­menes. Si bien la â€œprecrimenâ€ es ficciÃ³n, las tÃ©cnicas de tracking y detecciÃ³n existen desde hace aÃ±os.

### 5.1 Â¿QuÃ© es la VisiÃ³n por Ordenador?  
- Disciplina que **permite a las mÃ¡quinas â€˜verâ€™** y extraer informaciÃ³n de imÃ¡genes o secuencias de video.  
- Objetivos principales:  
  1. **Reconocer** quÃ© hay en la imagen (clasificaciÃ³n).  
  2. **Localizar** objetos (detecciÃ³n).  
  3. **Segmentar** regiones (pixel a pixel).  
  4. **Seguir** movimientos en video (tracking).  
  5. **Reconstruir** escenas en 3D.

### 5.2 Algoritmos ClÃ¡sicos vs. Deep Learning  
- **Enfoques ClÃ¡sicos (antes de las CNN)**:  
  - DetecciÃ³n de bordes (Canny), esquinas (Harris), descriptores (SIFT, SURF).  
  - SegmentaciÃ³n basada en umbrales (Otsu), clustering (k-means).  
  - Tracking con KLT (Lucas-Kanade).  
- **Enfoques Modernos (Deep Learning)**:  
  - Modelos CNN para clasificaciÃ³n, detecciÃ³n (R-CNN, SSD, YOLO), segmentaciÃ³n (U-Net, Mask R-CNN).  
  - Tracking basado en DeepSORT, Track R-CNN.  

---

## 6. Algoritmos Clave en VisiÃ³n por Ordenador  

### 6.1 Convolutional Neural Networks (CNN)  
- Ya descritas en el apartado 3.2, son la base de la mayorÃ­a de sistemas de visiÃ³n actuales.  
- **Aplicaciones prÃ¡cticas**:  
  - ClasificaciÃ³n de imÃ¡genes (e.g., reconocer dÃ­gitos en *Pac-Man*).  
  - ExtracciÃ³n de caracterÃ­sticas para tareas mÃ¡s avanzadas.  

### 6.2 YOLO (You Only Look Once)  
#### 6.2.1 Concepto General  
- **Family of One-Stage Detectors**: A diferencia de modelos en dos fases (R-CNN, Faster R-CNN), YOLO realiza detecciÃ³n en **un Ãºnico paso**:  
  1. Divide la imagen en una cuadrÃ­cula SÃ—S.  
  2. Cada celda predice un nÃºmero fijo de cajas (bounding boxes) + su grado de confianza + distribuciÃ³n de probabilidades de clases.  
  3. Filtra y refina esas cajas con Non-Maximum Suppression (NMS).  

#### 6.2.2 CaracterÃ­sticas Principales  
- **Velocidad**: Capaz de procesar video en tiempo real (e.g., 45 FPS en YOLOv3).  
- **PrecisiÃ³n**: Buen compromiso entre velocidad y exactitud.  
- **Escalabilidad**: Nuevas versiones (YOLOv4, v5, v6, YOLOv7â€¦) mejoran detecciÃ³n en pequeÃ±as instancias y en condiciones difÃ­ciles de luz o Ã¡ngulo.  

#### 6.2.3 Â¿CÃ³mo Trabaja YOLO?  
1. **DivisiÃ³n en cuadrÃ­cula**: Supongamos una imagen de 416Ã—416 px dividida en 13Ã—13 celdas.  
2. **PredicciÃ³n de Bounding Boxes**: Cada celda genera 3â€“5 cajas con coordenadas normalizadas (x, y, w, h) y una **confidence score** (probabilidad de que la caja contenga un objeto + quÃ© tan precisa es la caja).  
3. **ClasificaciÃ³n por celda**: Cada celda tambiÃ©n emite probabilidades para cada clase (e.g., persona, coche, bicicleta).  
4. **Filtrado**: Se eliminan cajas con baja confianza y se aplican NMS para descartar cajas superpuestas que representen el mismo objeto.  

> **AnalogÃ­a videojuego**: Imagina que cada celda es un â€œNPCâ€ en *Halo*, que intenta adivinar si un enemigo estÃ¡ cerca y en quÃ© direcciÃ³n, y todos coordinan para apuntar con precisiÃ³n sin duplicarse.  

---

## 7. Tareas Fundamentales en VisiÃ³n por Ordenador  

> **Escena cinematogrÃ¡fica**: En *Blade Runner 2049*, los holocubos podrÃ­an analizar cada gota de lluvia para detectar rostros, seguir a personajes y reconstruir la trayectoria de un objeto. Estas tareas reales (aunque mÃ¡s modestas) se apoyan en algoritmos de detecciÃ³n, segmentaciÃ³n y tracking.

### 7.1 DetecciÃ³n de Objetos (Object Detection)  
- **Objetivo**: Identificar y localizar (mediante bounding boxes) todas las instancias de ciertas clases de objetos en una imagen.  
- **Salida tÃ­pica**: Lista de (clase, caja delimitadora, confianza).  
- **Modelos clÃ¡sicos**:  
  - **R-CNN (Region-based CNN)**:  
    1. Propuesta de regiones (Selective Search).  
    2. CNN que extrae caracterÃ­sticas de cada regiÃ³n.  
    3. ClasificaciÃ³n + refinamiento de bounding boxes.  
  - **Fast/Faster R-CNN**: Integran la generaciÃ³n de propuestas con la red, mucho mÃ¡s rÃ¡pido.  
  - **SSD (Single Shot Detector)**: Similar a YOLO, un solo paso.  
  - **YOLO**: Descrito anteriormente.  

### 7.2 SegmentaciÃ³n de ImÃ¡genes (Image Segmentation)  
- **Objetivo**: Clasificar cada pÃ­xel de la imagen en una clase (segmentaciÃ³n semÃ¡ntica) o marcar instancias individuales (segmentaciÃ³n de instancia).  
- **Tipos**:  
  1. **SegmentaciÃ³n SemÃ¡ntica**: Cada pÃ­xel recibe una etiqueta (e.g., â€œparte de una sillaâ€, â€œparte del sueloâ€). No distingue entre multiples instancias de la misma clase.  
     - Modelos: FCN (Fully Convolutional Networks), U-Net, DeepLab.  
  2. **SegmentaciÃ³n de Instancia**: AdemÃ¡s de clasificar pÃ­xeles, separa instancias individuales (p. ej., silla_1, silla_2).  
     - Modelos: Mask R-CNN, PANet.  

> **Ejemplo prÃ¡ctico**: En agricultura de precisiÃ³n (imÃ¡genes de drones sobre campos de cultivo), la segmentaciÃ³n semÃ¡ntica permite distinguir distintos cultivos del suelo; la de instancia ayuda a contar plantas individuales para control de inventario.

### 7.3 Seguimiento de Objetos (Object Tracking)  
- **Objetivo**: Dado un objeto detectado en el primer frame de un video, seguir su trayectoria a lo largo de la secuencia.  
- **Tareas comunes**:  
  1. **Single Object Tracking (SOT)**: Seguimiento de un Ãºnico objeto en movimiento (p. ej., el balÃ³n en un partido de *FIFA*).  
  2. **Multiple Object Tracking (MOT)**: Seguimiento simultÃ¡neo de mÃºltiples objetos (p. ej., peatones en un cruce de trÃ¡fico).  
- **Enfoques clÃ¡sicos**:  
  - **KCF (Kernelized Correlation Filters)**, MOSSE.  
  - **CamShift (Continuously Adaptive Mean Shift)**.  
- **Enfoques modernos (Deep Learning)**:  
  - **DeepSORT**: Combina detecciÃ³n (ej. YOLO) con un mÃ³dulo de â€œre-identificaciÃ³nâ€ basado en CNN para asociar el mismo objeto en distintos frames.  
  - **Track R-CNN**: Extiende Mask R-CNN para realizar detecciones y tracking simultÃ¡neamente.  

> **AnalogÃ­a cinematogrÃ¡fica**: En *El Origen*, Cobb necesita seguir mentalmente a varios personajes en diferentes niveles de sueÃ±o (niveles de â€œframesâ€ sucesivos) para coordinar el â€œkickâ€ final. El tracking en visiÃ³n hace un trabajo similar, manteniendo la identidad de cada objeto a lo largo del tiempo.

---

## 8. Resumen de Diferencias Entre Tareas  

| Tarea                    | Objetivo principal                                                   | Salida tÃ­pica                               | Algoritmos comunes                                |
|--------------------------|----------------------------------------------------------------------|---------------------------------------------|---------------------------------------------------|
| **ClasificaciÃ³n de Imagen** | Determinar la clase predominante de toda la imagen                 | Etiqueta Ãºnica (p. ej., â€œgatoâ€)             | ResNet, VGG, Inception, EfficientNet              |
| **DetecciÃ³n de Objetos** | Localizar y clasificar mÃºltiples objetos en una misma imagen         | Bounding boxes + etiquetas                  | R-CNN, Faster R-CNN, SSD, YOLO, RetinaNet         |
| **SegmentaciÃ³n SemÃ¡ntica** | Etiquetar cada pÃ­xel con una clase (sin distinguir instancias)      | Mapa de clases (imagen de tamaÃ±o original)  | FCN, U-Net, DeepLab, SegNet                       |
| **SegmentaciÃ³n de Instancia** | Etiquetar cada pÃ­xel y separar instancias individuales            | Mapas de mÃ¡scaras para cada instancia       | Mask R-CNN, PANet, YOLACT                           |
| **Tracking de Objetos**  | Seguir la trayectoria de uno o varios objetos a lo largo de un video | Secuencia de bounding boxes con ID constante | KCF, MOSSE, CamShift, DeepSORT, Track R-CNN       |

---

## 9. Ejemplos de AplicaciÃ³n en el Curso  

1. **Reconocimiento de Rostros para Seguridad**  
   - **DetecciÃ³n**: YOLO localiza rostros en la imagen.  
   - **SegmentaciÃ³n**: Mask R-CNN recorta con precisiÃ³n las regiones faciales.  
   - **Tracking**: DeepSORT sigue personas en ambientes de vigilancia.  
   - **Caso friki**: En *Skyfall* (James Bond), los sistemas Skyfall Analytics combinan detecciÃ³n y tracking para seguir a Bond y villanos en tiempo real (Â¡un poco exagerado, pero cercano a lo que haremos con las tÃ©cnicas bÃ¡sicas!).

2. **Control de Calidad en Manufactura**  
   - **DetecciÃ³n de defectos**: Una CNN entrenada reconoce araÃ±azos o imperfecciones en piezas metÃ¡licas.  
   - **SegmentaciÃ³n de instancias**: U-Net identifica las Ã¡reas defectuosas pixel a pixel.  
   - **Tracking**: En una lÃ­nea de producciÃ³n, se sigue cada pieza para registrar estadÃ­sticas.  

3. **Juegos y Realidad Aumentada (AR)**  
   - **DetecciÃ³n de superficies**: Modelos CNN detectan superficies planas en tiempo real para proyectar elementos virtuales (como en *PokÃ©mon Go* al capturar Pikachu).  
   - **Tracking de manos**: Deep Learning permite que, en *Half-Life: Alyx*, el casco VR reconozca la posiciÃ³n de la mano para interactuar con objetos.  

---

## 10. QuÃ© Veremos en el Curso  

1. **Fundamentos de VisiÃ³n por Ordenador**  
   - Historia, aplicaciones cotidianas, responsabilidades Ã©ticas (p. ej., privacidad, sesgos en datos).  
   - Procesamiento de imÃ¡genes clÃ¡sicas (filtros, morfologÃ­a).  

2. **Aprendizaje AutomÃ¡tico & Deep Learning para VisiÃ³n**  
   - Entrenamiento de modelos: conjuntos de datos (ImageNet, COCO).  
   - Arquitecturas CNN bÃ¡sicas: LeNet, AlexNet, VGG, ResNet.  
   - Transfer Learning: reutilizar pesos entrenados en grandes bases de datos.  

3. **DetecciÃ³n y SegmentaciÃ³n**  
   - R-CNN, Fast/Faster R-CNN, SSD, YOLO (versiones y mejoras).  
   - U-Net, Mask R-CNN, DeepLab.  

4. **Tracking de Objetos en Secuencias de Video**  
   - MÃ©tricas de evaluaciÃ³n (MOTA, MOTP).  
   - Algoritmos clÃ¡sicos vs. DeepSORT.  

5. **VisiÃ³n 3D y Realidad Aumentada**  
   - ReconstrucciÃ³n 3D: estereo, SLAM, Point Clouds.  
   - Aplicaciones a videojuegos y entornos virtuales.  

6. **Proyectos PrÃ¡cticos con TensorFlow y OpenCV**  
   - DetecciÃ³n en tiempo real con YOLOv5 + cÃ¡mara web.  
   - SegmentaciÃ³n de semÃ¡foros en video de drones.  
   - Seguimiento de vehÃ­culos usando DeepSORT + YOLO.  

---

## 11. ConclusiÃ³n  

Este curso de **VisiÃ³n por Ordenador** te adentrarÃ¡ en cÃ³mo pasar **de pÃ­xeles a datos** Ãºtiles, combinando teorÃ­a y prÃ¡ctica. AprenderÃ¡s desde la teorÃ­a de **tipos de IA** y **aprendizaje automÃ¡tico** hasta la implementaciÃ³n de sistemas reales en **Deep Learning** (CNNs, YOLO, Mask R-CNN, etc.).  

Â¡PrepÃ¡rate para â€œverâ€ el mundo con ojos de mÃ¡quina! En cada tema, vincularemos conceptos con ejemplos frikis del cine y los videojuegos para que el aprendizaje sea ameno y relevante.  

---

> **Nota final**: No importa si al inicio las redes neuronales te parecen complejas; como en los videojuegos, la prÃ¡ctica constante (y las â€œvidas extraâ€ en forma de ejercicios y ejemplos) te harÃ¡n dominar estas tÃ©cnicas. ğŸš€  