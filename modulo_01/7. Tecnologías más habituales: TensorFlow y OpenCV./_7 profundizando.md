<!-- Tabla de contenidos -->
- [Tecnolog√≠as principales en visi√≥n por ordenador](#tecnolog√≠as-principales-en-visi√≥n-por-ordenador)
  - [1. TensorFlow](#1-tensorflow)
    - [1.1 Ecosistema y componentes](#11-ecosistema-y-componentes)
    - [1.2 Fortalezas en visi√≥n](#12-fortalezas-en-visi√≥n)
    - [1.3 Facilidad de desarrollo](#13-facilidad-de-desarrollo)
    - [1.4 Escalabilidad y despliegue](#14-escalabilidad-y-despliegue)
  - [2. OpenCV (Open Source Computer Vision Library)](#2-opencv-open-source-computer-vision-library)
    - [2.1 Base y algoritmos cl√°sicos](#21-base-y-algoritmos-cl√°sicos)
    - [2.2 Integraci√≥n multiplataforma](#22-integraci√≥n-multiplataforma)
    - [2.3 Casos de uso y ejemplos ‚Äúfriky‚Äù](#23-casos-de-uso-y-ejemplos-friky)
    - [2.4 Preprocesamiento para deep learning](#24-preprocesamiento-para-deep-learning)
  - [3. PyTorch](#3-pytorch)
    - [3.1 Filosof√≠a ‚Äúdefine-by-run‚Äù](#31-filosof√≠a-define-by-run)
    - [3.2 Ecosistema TorchVision](#32-ecosistema-torchvision)
    - [3.3 Transici√≥n a producci√≥n](#33-transici√≥n-a-producci√≥n)
  - [4. Otras tecnolog√≠as relevantes](#4-otras-tecnolog√≠as-relevantes)
    - [4.1 Scikit-image y PIL/Pillow](#41-scikit-image-y-pilpillow)
    - [4.2 YOLO (You Only Look Once)](#42-yolo-you-only-look-once)
    - [4.3 MediaPipe](#43-mediapipe)
    - [4.4 Detectron2](#44-detectron2)
    - [4.5 Hugging Face Transformers (visi√≥n)](#45-hugging-face-transformers-visi√≥n)
  - [5. Integraci√≥n y flujos de trabajo t√≠picos](#5-integraci√≥n-y-flujos-de-trabajo-t√≠picos)
    - [5.1 Pipeline h√≠brido](#51-pipeline-h√≠brido)
    - [5.2 Desarrollo iterativo: Investigaci√≥n ‚Üí Producci√≥n](#52-desarrollo-iterativo-investigaci√≥n-‚Üí-producci√≥n)
    - [5.3 Optimizaci√≥n en dispositivos embebidos](#53-optimizaci√≥n-en-dispositivos-embebidos)
    - [5.4 Cloud computing y despliegue](#54-cloud-computing-y-despliegue)
- [Ap√©ndice: Esquema general de un proyecto de visi√≥n por ordenador](#ap√©ndice-esquema-general-de-un-proyecto-de-visi√≥n-por-ordenador)

---

# Tecnolog√≠as principales en visi√≥n por ordenador

Este documento adapta y ampl√≠a los apuntes originales, estructur√°ndolos en **Markdown** para GitHub. Hemos a√±adido tablas comparativas, ejemplos ‚Äúfriky‚Äù (basados en el cine y videojuegos) y un esquema para facilitar el estudio. ¬°Que la Fuerza Friky te acompa√±e! üé¨üëæ

---

## 1. TensorFlow

TensorFlow es la plataforma de machine learning m√°s utilizada a nivel mundial (o al menos la m√°s mencionada en foros de StackOverflow durante la √∫ltima d√©cada). Desarrollada por Google, ofrece un ecosistema muy completo:

### 1.1 Ecosistema y componentes

| Componente        | Descripci√≥n                                                                 | Analogia Friky                                 |
|-------------------|------------------------------------------------------------------------------|------------------------------------------------|
| **TensorFlow Core**   | Biblioteca central para dise√±ar, entrenar y ejecutar modelos de deep learning. | El ‚ÄúReactor Arc‚Äù de Iron Man: potencia todo     |
| **TensorFlow Lite**   | Versi√≥n ligera para dispositivos m√≥viles y microcontroladores.                 | El ‚ÄúBatarang‚Äù de Batman: peque√±o pero letal     |
| **TensorFlow.js**     | Para ejecutar y entrenar modelos directamente en el navegador.                | ¬øRecuerdas Skeletor invadiendo Internet?        |
| **TensorFlow Hub**    | Repositorio de modelos pre-entrenados (ResNet, EfficientNet, YOLO, etc.).    | La ‚ÄúBiblioteca Jedi‚Äù con paquetes listos para usar |
| **Keras (integrado)** | API de alto nivel para construir redes, m√°s intuitiva que leer un manual de Inception. | La Capa del Olor de Narciso (f√°cil de poner)  |

#### Resumen r√°pido

- **Ecosistema integral**: Desde el Core hasta TensorFlow Lite/JS.
- **Modelos preentrenados**: ResNet, EfficientNet, MobileNet, YOLO en TF Hub.
- **Despliegue en nube**: Integraci√≥n nativa con Google Cloud AI Platform.

### 1.2 Fortalezas en visi√≥n

- **Colecci√≥n de modelos**: Disponibles en TF Hub, cubren clasificaci√≥n, detecci√≥n de objetos, segmentaci√≥n, etc.
- **TensorFlow Object Detection API**:  
  - Bibliotecas y ejemplos listos para detectar personas, coches, animales.  
  - Tutoriales y notebooks oficiales que parecen salir de ‚ÄúEl laboratorio de Dexter‚Äù.
- **Eager Execution**: Debugging m√°s interactivo, ¬°como si Jarvis te respondiera al instante!
- **tf.data**:  
  - Pipelines optimizados para cargar, transformar y alimentar im√°genes.  
  - Ventaja: procesamiento paralelo en CPU/GPU, ideal para datasets con millones de im√°genes (piensa en los planos de ‚ÄúEl Se√±or de los Anillos‚Äù: toneladas de datos).

### 1.3 Facilidad de desarrollo

- **Keras integrado**:  
  - API de alto nivel con clases `Sequential` y `Model`.  
  - Similar a armar una partida de Lego: encajas bloques de capas y ya funciona.
- **Eager Execution por defecto**:  
  - Similar al ‚ÄúModo Dios‚Äù en videojuegos: ves los valores de los tensores al vuelo.  
  - Facilita prototipado r√°pido.
- **tf.keras.callbacks**:  
  - Callbacks como EarlyStopping, ModelCheckpoint, TensorBoard (visualizaci√≥n tipo ‚ÄúThe Matrix‚Äù).  

### 1.4 Escalabilidad y despliegue

- **Entrenamiento distribuido**:  
  - `tf.distribute.Strategy` para m√∫ltiples GPUs/TPUs.  
  - ‚ÄúRed Eyeshield 21‚Äù entrenando en varios GPUs a la vez.  
- **TPUs de Google**:  
  - Hardware especializado para operaciones tens√≥ricas.  
  - Igualito que subirte al Halc√≥n Milenario para hacer warp speed en tu entrenamiento.
- **Google Cloud Platform (GCP)**:  
  - Integraci√≥n nativa con AI Platform, AI Notebooks y Dataflow.  
  - Despliegue tipo ‚ÄúTony Stark‚Äù con un clic.
  
---

## 2. OpenCV (Open Source Computer Vision Library)

OpenCV existe desde hace m√°s de 20 a√±os y es la piedra angular de la visi√≥n tradicional. Si TensorFlow es el Quijote del deep learning, OpenCV es Sancho Panza en la visi√≥n cl√°sica.

### 2.1 Base y algoritmos cl√°sicos

- **Filtrado de im√°genes**:  
  - Filtros espaciales (blur, GaussianBlur, medianBlur), detecci√≥n de bordes (Canny), etc.  
  - Ejemplo friky: aplicar un filtro de Canny y parecer el ‚ÄúOjo del Sauron‚Äù.
- **Transformaciones geom√©tricas**:  
  - Rotaciones, escalados, transformaciones afines y perspectiva (warpPerspective).  
  - Es como cambiar la c√°mara en ‚ÄúResident Evil‚Äù: giras la vista para explorar.
- **Calibraci√≥n de c√°maras**:  
  - Estimaci√≥n de par√°metros intr√≠nsecos y extr√≠nsecos con tableros de ajedrez.  
  - Piensa en la escena de "Up": alineando m√∫ltiples perspectivas para hacer el efecto de profundidad.
- **Detecci√≥n de bordes y caracter√≠sticas**:  
  - Harris, Shi-Tomasi (goodFeaturesToTrack), SIFT (si tienes licencia), SURF, ORB.  
  - Ejemplo: detectar esquinas como si fuera el ‚ÄúMapa del Troll‚Äù en ‚ÄúHarry Potter‚Äù.

### 2.2 Integraci√≥n multiplataforma

| Lenguaje     | Plataformas Soportadas                  | Casos de Uso M√°s Comunes                                 |
|--------------|-----------------------------------------|----------------------------------------------------------|
| **C++**      | Windows, Linux, macOS, Android, iOS     | Aplicaciones embebidas en rob√≥tica (ROS), sistemas de c√°maras de seguridad. |
| **Python**   | Windows, Linux, macOS                   | Prototipo r√°pido, scripting en pipelines de visi√≥n.      |
| **Java/Android** | Android                              | Apps m√≥viles que usan la c√°mara para escanear c√≥digos o reconocer objetos. |
| **Java (desktop)** | Windows, Linux, macOS              | Aplicaciones empresariales de visi√≥n industrial.         |
| **Otros (C#, MATLAB, etc.)** | Mediante wrappers                | Integraciones con entornos acad√©micos o empresariales.   |

- **Rendimiento en tiempo real**:  
  - Buenas implementaciones en C++ con optimizaciones SSE/NEON.  
  - Permite procesar streams de v√≠deo a 30‚Äì60 FPS sin despeinarse (incluso en Raspberry Pi, el Frod√≥n de los SBC).

### 2.3 Casos de uso y ejemplos ‚Äúfriky‚Äù

- **SLAM (Simultaneous Localization And Mapping)**:  
  - Librer√≠a `cv::aruco` para marcadores, `ORB-SLAM2`.  
  - Ejemplo: ‚ÄúPac-Man‚Äù construyendo el mapa mientras come bolitas.
- **Stereo vision**:  
  - Calcular disparidad con `StereoBM` o `StereoSGBM`.  
  - Ejemplo ‚Äúfriky‚Äù: Mida la distancia del Dr. Robotnik con dos ‚Äúojos‚Äù como C-3PO.
- **Optical Flow**:  
  - Lucas-Kanade, Farneback.  
  - Ejemplo: seguimiento de la pelota en un partido de ‚ÄúFIFA‚Äù para analizar la trayectoria.
- **Reconocimiento facial (Eigenfaces/Fisherfaces)**:  
  - Un cl√°sico que te hace sentir en una pel√≠cula de los 90 (‚ÄúMen In Black‚Äù).
  
### 2.4 Preprocesamiento para deep learning

- **Detecci√≥n y correcci√≥n de iluminaci√≥n**:  
  - Ecualizaci√≥n de histogramas (CLAHE), correcci√≥n gamma.  
  - Como los ‚Äúcontras‚Äù en TMNT: ajustan la iluminaci√≥n para que todo brille.
- **Ajuste de tama√±o y normalizaci√≥n**:  
  - `cv2.resize`, conversi√≥n a tensores para TensorFlow/PyTorch.  
  - ¬°C√≥mo convertir una c√°mara VHS en formato digital HD!
- **Segmentaci√≥n cl√°sica**:  
  - Umbralizaci√≥n, K-means en espacio de color HSV, Watershed.  
  - Ejemplo: ‚ÄúMario Kart‚Äù segmentando la pista de carrera del fondo.
  
---

## 3. PyTorch

PyTorch, desarrollado por Facebook (Meta), es el framework ‚Äúhipster‚Äù de los investigadores de deep learning. Si TensorFlow es Tony Stark, PyTorch es Doctor Strange: din√°mico, flexible y perfecto para experimentos surrealistas.

### 3.1 Filosof√≠a ‚Äúdefine-by-run‚Äù

- **Grafos din√°micos**:  
  - Cada operaci√≥n se construye en tiempo de ejecuci√≥n.  
  - Control total en cada iteraci√≥n, como jugar con ‚ÄúThe Legend of Zelda‚Äù y poder girar el mundo a tu antojo.
- **Facilidad de debugging**:  
  - Inspeccionas tensores con `print()` o `pdb.set_trace()` sin complicaciones.  
  -‚ÅüComparaci√≥n: como usar el ‚ÄúModo Dios‚Äù en ‚ÄúSkyrim‚Äù para ver valores internos.

### 3.2 Ecosistema TorchVision

- **Datasets predefinidos**:  
  - `CIFAR10`, `ImageNet`, `COCO`, etc.  
  - Cargas con un par de l√≠neas:  
    ```python
    from torchvision import datasets, transforms
    transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])
    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    ```
- **Transformaciones optimizadas**:  
  - `transforms.RandomCrop`, `transforms.ColorJitter`, `transforms.Normalize`.  
  - Como un mod de ‚ÄúFallout‚Äù que transforma texturas al vuelo.
- **Modelos preentrenados**:  
  - `resnet50`, `densenet121`, `vgg16`, `efficientnet_b0`, Vision Transformers (ViT).  
  - Listos para usar con transferencia de aprendizaje.

### 3.3 Transici√≥n a producci√≥n

- **TorchScript**:  
  - Convierte tu modelo din√°mico a un grafo est√°tico optimizado.  
  - Canon: ‚ÄúConvi√©rtete a hierro, modelito de AI‚Äù, al estilo de ‚ÄúTransformers‚Äù.
- **TorchServe**:  
  - Servidor para desplegar modelos como endpoints REST.  
  - Perfecto para montar tu propio Jarvis al estilo Tony Stark en la nube.
- **PyTorch Lightning** (opcional):  
  - Estructura el c√≥digo para separar entrenamiento, validaci√≥n y testing.  
  - Si eres fan de ‚ÄúThe Avengers‚Äù, te ayuda a coordinar a todos los h√©roes en un solo plan.

---

## 4. Otras tecnolog√≠as relevantes

Adem√°s de los grandes protagonistas, existen muchas librer√≠as y frameworks que pueden complementar tu proyecto de visi√≥n por ordenador. A continuaci√≥n, una lista con sus principales caracter√≠sticas y ejemplos frikis.

### 4.1 Scikit-image y PIL/Pillow

| Biblioteca       | Enfoque                   | Lenguaje  | Funciones clave                                  | Ejemplo friky                                            |
|------------------|---------------------------|-----------|--------------------------------------------------|----------------------------------------------------------|
| **Scikit-image** | Procesamiento cient√≠fico  | Python    | Segmentaci√≥n (Otsu, SLIC), an√°lisis de regiones, m√©tricas de calidad | Como el ‚ÄúHechizo Patronus‚Äù en Harry Potter: detecta lo bueno de lo malo. |
| **PIL/Pillow**   | Manipulaci√≥n b√°sica de im√°genes | Python | Redimensionar, rotar, recortar, conversi√≥n de formatos | Como un editor de texto en ‚ÄúThe Legend of Zelda‚Äù: simple pero esencial. |

- **Scikit-image**:  
  - Ideal para an√°lisis de im√°genes m√©dicas o cient√≠ficas.  
  - Funciones avanzadas como transformada de Hough (detectar l√≠neas y c√≠rculos), etiquetas de objetos.
- **PIL/Pillow**:  
  - Sencillo, r√°pido.  
  - Carga/guarda en JPG, PNG, GIF, BMP.  
  - √ötil para pipelines de preprocesamiento ligero antes de soltar el data en TensorFlow o PyTorch.

### 4.2 YOLO (You Only Look Once)

- **Arquitectura de detecci√≥n en tiempo real**:  
  - Detecta y clasifica objetos en una sola pasada (versus R-CNN que va de dos en dos).  
  - Como el Flash en The Flash: ve todo en un solo vistazo.
- **Versiones m√°s populares**:  
  - **YOLOv5**: PyTorch, ligero, r√°pido (~45 FPS en GPU moderada).  
  - **YOLOv8**: Ultraligero, mejoras de precisi√≥n y velocidad.  
  - **YOLOv11** (comunidad): Experimentaciones con detectores m√°s r√°pidos.  
- **Tabla comparativa de YOLO vs R-CNN**:

| Caracter√≠stica              | YOLOv5                                 | Faster R-CNN                          |
|-----------------------------|----------------------------------------|---------------------------------------|
| Velocidad (FPS)             | ‚âà45 FPS en GPU moderada                | ‚âà5‚Äì10 FPS                             |
| Precisi√≥n (mAP COCO)        | 45‚Äì55 (depende de la versi√≥n)          | 42‚Äì52                                 |
| Complejidad de entrenamiento| M√°s sencillo, scripts oficiales ligeros| Requiere pasos: region proposals + clasificaci√≥n |
| Uso en friky-world          | Juegos en tiempo real (detecci√≥n de enemigos al vuelo) | An√°lisis forense de v√≠deo (CSI style) |

### 4.3 MediaPipe

- **Framework de Google para an√°lisis multimedia**:  
  - Preconfigurado para detecci√≥n de pose humana, reconocimiento facial, seguimiento de manos, segmentaci√≥n de selfies.  
  - Listo para m√≥vil (Android/iOS).  
- **Casos de uso friky**:  
  - Realidad aumentada: poner m√°scara de Darth Vader en tu cara.  
  - Seguimiento de manos: simular hechizos de ‚ÄúDragon Ball‚Äù con tus movimientos.  
  - Detecci√≥n de pose: recrear la coreograf√≠a de ‚ÄúThriller‚Äù de Michael Jackson.

### 4.4 Detectron2

- **Plataforma de investigaci√≥n de Facebook (Meta)**:  
  - Implementa state-of-the-art en detecci√≥n y segmentaci√≥n: Mask R-CNN, RetinaNet, DensePose.  
  - Modular y r√°pido para experimentar con arquitecturas nuevas.  
- **Ejemplo friky**:  
  - Usarlo para segmentar personajes en la escena final de ‚ÄúAvengers: Endgame‚Äù y analizarlos por separado.

### 4.5 Hugging Face Transformers (visi√≥n)

- **Origen en NLP, ahora multimodal**:  
  - Modelos como ViT (Vision Transformer), CLIP (visi√≥n + lenguaje).  
  - Facilita acceso a checkpoints entrenados en grandes datasets (ImageNet, LAION).  
- **Aplicaciones**:  
  - B√∫squeda de im√°genes sem√°ntica (‚Äú¬øD√≥nde est√° el Halc√≥n Milenario?‚Äù).  
  - Clasificaci√≥n de escenas al estilo ‚ÄúCazafantasmas‚Äù: identifica si hay ‚Äúproto-hombre‚Äù en la imagen.
- **Integraci√≥n sencilla**:  
  - Con un par de l√≠neas cargas un ViT y lo aplicas a clasificar tus propias capturas de pantalla de videojuegos.

---

## 5. Integraci√≥n y flujos de trabajo t√≠picos

### 5.1 Pipeline h√≠brido

La mayor√≠a de proyectos combinan varias herramientas para aprovechar fortalezas de cada una. A continuaci√≥n, un **esquema** (mermaid) de un flujo de trabajo t√≠pico:

```mermaid
flowchart TD
  A[üì∑ Captura de video/im√°genes] --> B[‚öôÔ∏è Preprocesamiento (OpenCV, PIL)]
  B --> C[üîç Detecci√≥n cl√°sica / Segmentaci√≥n inicial (OpenCV, Scikit-image)]
  C --> D[ü§ñ Inferencia Deep Learning (TensorFlow / PyTorch)]
  D --> E[üîÑ Post-procesamiento (OpenCV, custom scripts)]
  E --> F[üöÄ Despliegue (API REST, App m√≥vil, Embedded)]
```

  	A ‚Üí B:
	Captura de c√°mara en vivo o carga de dataset (OpenCV).
	Ajuste de tama√±o, correcci√≥n de color, aumento de datos.
	B ‚Üí C:
	Aplicar filtros, detecci√≥n de contornos, m√°scaras para aislar regiones de inter√©s.
	Ejemplo: en ‚ÄúGhostbusters‚Äù, primero aislas la ‚ÄúDepredador‚Äù (ecto-plasma) antes de analizarlo con un modelo.
	C ‚Üí D:
	Entrenamiento o inferencia de un modelo CNN/CNN 3D/Transformer.
	Ejemplo friky: tu modelo detecta al T-800 (Terminator) en un plano retroiluminado.
	D ‚Üí E:
	Filtrado de falsos positivos, tracking de objetos (DeepSORT).
	Ejemplo: en ‚ÄúThe Last of Us Part II‚Äù, rastreas al enemigo cazador en plena noche.
	E ‚Üí F:
	Devolver coordenadas, bounding boxes o m√°scaras.
	Despliegue en un API (TorchServe, TensorFlow Serving) o sube a un dispositivo m√≥vil (TensorFlow Lite, PyTorch Mobile).



5.2 Desarrollo iterativo: Investigaci√≥n ‚Üí Producci√≥n

| Fase                          | Herramientas t√≠picas                                        | Objetivo                                                          |
|-------------------------------|-------------------------------------------------------------|-------------------------------------------------------------------|
| I. Prototipado                | PyTorch (r√°pido), Jupyter Notebooks, OpenCV                 | Explorar ideas, probar arquitecturas, debugging ‚Äúon the fly‚Äù      |
| II. Entrenamiento a gran escala | TensorFlow (distribuido en TPUs/GPU), PyTorch con DDP       | Escalar al dataset completo, optimizar hiperpar√°metros            |
| III. Validaci√≥n y benchmarking | TensorBoard, MLflow, comet.ml                                | Monitorizar m√©tricas: accuracy, mAP, IOU, F1-score               |
| IV. Conversi√≥n de modelo       | TorchScript, ONNX, TensorFlow SavedModel                     | Obtener formato optimizado para producci√≥n                         |
| V. Despliegue                  | TensorFlow Serving, TorchServe, Flask/FastAPI, Docker, Kubernetes | Servir como microservicio, empaquetar en contenedores             |
| VI. Mantenimiento              | ML Monitoring Tools (Prometheus, Grafana)                    | Vigilar drift, rendimiento en producci√≥n                           |



	‚Ä¢	Ejemplo friky:
	1.	En Phase I, tu modelo detecta Pok√©mons en pantallas de Mario.
	2.	En Phase II, entrenas en cientos de horas de gameplay de Twitch.
	3.	En Phase III, comparas m√©tricas con v1.
	4.	En Phase IV, conviertes tu modelo para que corra en un smartphone (TensorFlow Lite + GPU delegado).
	5.	En Phase V, lo lanzas como app de AR que detecta Pok√©mons en la calle.
	6.	En Phase VI, monitoreas la tasa de falsos positivos cuando sale un Charizard nuevos en la Galar Region.

5.3 Optimizaci√≥n en dispositivos embebidos
	‚Ä¢	TensorFlow Lite:
	‚Ä¢	Conversi√≥n .tflite, cuantizaci√≥n (int8, float16), delegados de GPU (Android), Coral Edge TPU.
	‚Ä¢	Ejemplo: tu Raspberry Pi 4 interpretando se√±ales de Mario Kart en HD.
	‚Ä¢	PyTorch Mobile:
	‚Ä¢	torch.quantization, conversi√≥n a TorchScript, arquitectura optimizada.
	‚Ä¢	Ideal para iOS/Android (XCode, Android Studio).
	‚Ä¢	OpenCV compilado para ARM:
	‚Ä¢	Utiliza NEON, V4L2 para captura en tiempo real.
	‚Ä¢	Ejemplo ‚Äúfriky‚Äù: Detecci√≥n de intrusos al estilo ‚ÄúSilent Hill‚Äù con una c√°mara Pi Zero.

5.4 Cloud computing y despliegue
	‚Ä¢	AWS SageMaker, GCP AI Platform, Azure ML:
	‚Ä¢	Entrena sin preocuparte de la infraestructura (como si el jefe final ya estuviera resuelto).
	‚Ä¢	Paga por instancia solo cuando entrenas (¬°adi√≥s a los sem√°foros eternos!).
	‚Ä¢	Serverless Inference:
	‚Ä¢	AWS Lambda + AWS SageMaker Endpoint, GCP Cloud Functions + Vertex AI.
	‚Ä¢	Ejecuci√≥n a demanda, escalado autom√°tico.
	‚Ä¢	Edge Computing:
	‚Ä¢	Google Coral, NVIDIA Jetson Nano, Intel Movidius.
	‚Ä¢	Ideal para rob√≥tica, drones o veh√≠culos aut√≥nomos (KITT en un Ford Mustang).

‚∏ª

Ap√©ndice: Esquema general de un proyecto de visi√≥n por ordenador

Para ayudar a memorizar y estudiar, presentamos un esquema con los pasos principales, como si fuera un cheat sheet de videojuegos:

1. Definici√≥n del problema
   ‚îú‚îÄ Tipo de tarea: clasificaci√≥n, detecci√≥n, segmentaci√≥n, tracking
   ‚îú‚îÄ Dataset: tama√±o, formato, etiquetas
   ‚îî‚îÄ M√©tricas: accuracy, mAP, IOU, F1-score

2. Recolecci√≥n y preprocesamiento de datos
   ‚îú‚îÄ Captura de im√°genes/v√≠deo (OpenCV, c√°maras)
   ‚îú‚îÄ Limpieza y etiquetado (LabelImg, CVAT)
   ‚îú‚îÄ Aumento de datos (rotaciones, flip, cambios de brillo)
   ‚îî‚îÄ Divisi√≥n en entrenamiento/validaci√≥n/test

3. Selecci√≥n de arquitectura
   ‚îú‚îÄ Modelos cl√°sicos: SVM, HOG+SVM, Haar Cascades (OpenCV)
   ‚îú‚îÄ Modelos CNN: ResNet, MobileNet, EfficientNet
   ‚îú‚îÄ Modelos de detecci√≥n: YOLO, SSD, Faster R-CNN
   ‚îî‚îÄ Modelos de segmentaci√≥n: U-Net, Mask R-CNN

4. Entrenamiento
   ‚îú‚îÄ Framework: PyTorch (define-by-run) o TensorFlow (est√°tico/din√°mico)
   ‚îú‚îÄ Configuraci√≥n: tasas de aprendizaje, optimizadores (Adam, SGD)
   ‚îú‚îÄ Callbacks/Checkpoints (TensorBoard, ModelCheckpoint)
   ‚îî‚îÄ Validaci√≥n temprana (EarlyStopping)

5. Evaluaci√≥n y ajuste
   ‚îú‚îÄ M√©tricas clave: matriz de confusi√≥n, curvas ROC, PR
   ‚îú‚îÄ Ajuste de hiperpar√°metros (Grid Search, Bayesian Search)
   ‚îú‚îÄ Data Augmentation adicional si hay overfitting
   ‚îî‚îÄ Pruebas en dataset real (robustez en escenarios ‚Äúno perfectos‚Äù)

6. Conversi√≥n y optimizaci√≥n
   ‚îú‚îÄ PyTorch ‚Üí TorchScript ‚Üí Podar y cuantizar
   ‚îú‚îÄ TensorFlow ‚Üí SavedModel ‚Üí .tflite + cuantizaci√≥n
   ‚îú‚îÄ ONNX como puente entre frameworks
   ‚îî‚îÄ Benchmarking en hardware objetivo

7. Despliegue
   ‚îú‚îÄ Microservicios: TorchServe, TensorFlow Serving, FastAPI
   ‚îú‚îÄ Contenedores: Docker + Kubernetes (yak, minikube)
   ‚îú‚îÄ Edge: TensorFlow Lite, PyTorch Mobile, OpenCV compilado
   ‚îî‚îÄ Monitoreo y mantenimiento (Prometheus, Grafana)

8. Mantenimiento y escalado
   ‚îú‚îÄ Re-entrenamiento con datos nuevos (drift detection)
   ‚îú‚îÄ Monitoreo de m√©tricas en producci√≥n
   ‚îú‚îÄ Actualizaciones peri√≥dicas del modelo
   ‚îî‚îÄ Documentaci√≥n y versi√≥n de c√≥digo (GitHub, DVC)