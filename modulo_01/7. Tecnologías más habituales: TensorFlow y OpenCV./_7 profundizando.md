<!-- Tabla de contenidos -->
- [TecnologÃ­as principales en visiÃ³n por ordenador](#tecnologÃ­as-principales-en-visiÃ³n-por-ordenador)
  - [1. TensorFlow](#1-tensorflow)
    - [1.1 Ecosistema y componentes](#11-ecosistema-y-componentes)
    - [1.2 Fortalezas en visiÃ³n](#12-fortalezas-en-visiÃ³n)
    - [1.3 Facilidad de desarrollo](#13-facilidad-de-desarrollo)
    - [1.4 Escalabilidad y despliegue](#14-escalabilidad-y-despliegue)
  - [2. OpenCV (Open Source Computer Vision Library)](#2-opencv-open-source-computer-vision-library)
    - [2.1 Base y algoritmos clÃ¡sicos](#21-base-y-algoritmos-clÃ¡sicos)
    - [2.2 IntegraciÃ³n multiplataforma](#22-integraciÃ³n-multiplataforma)
    - [2.3 Casos de uso y ejemplos â€œfrikyâ€](#23-casos-de-uso-y-ejemplos-friky)
    - [2.4 Preprocesamiento para deep learning](#24-preprocesamiento-para-deep-learning)
  - [3. PyTorch](#3-pytorch)
    - [3.1 FilosofÃ­a â€œdefine-by-runâ€](#31-filosofÃ­a-define-by-run)
    - [3.2 Ecosistema TorchVision](#32-ecosistema-torchvision)
    - [3.3 TransiciÃ³n a producciÃ³n](#33-transiciÃ³n-a-producciÃ³n)
  - [4. Otras tecnologÃ­as relevantes](#4-otras-tecnologÃ­as-relevantes)
    - [4.1 Scikit-image y PIL/Pillow](#41-scikit-image-y-pilpillow)
    - [4.2 YOLO (You Only Look Once)](#42-yolo-you-only-look-once)
    - [4.3 MediaPipe](#43-mediapipe)
    - [4.4 Detectron2](#44-detectron2)
    - [4.5 Hugging Face Transformers (visiÃ³n)](#45-hugging-face-transformers-visiÃ³n)
  - [5. IntegraciÃ³n y flujos de trabajo tÃ­picos](#5-integraciÃ³n-y-flujos-de-trabajo-tÃ­picos)
    - [5.1 Pipeline hÃ­brido](#51-pipeline-hÃ­brido)
    - [5.2 Desarrollo iterativo: InvestigaciÃ³n â†’ ProducciÃ³n](#52-desarrollo-iterativo-investigaciÃ³n-â†’-producciÃ³n)
    - [5.3 OptimizaciÃ³n en dispositivos embebidos](#53-optimizaciÃ³n-en-dispositivos-embebidos)
    - [5.4 Cloud computing y despliegue](#54-cloud-computing-y-despliegue)
- [ApÃ©ndice: Esquema general de un proyecto de visiÃ³n por ordenador](#apÃ©ndice-esquema-general-de-un-proyecto-de-visiÃ³n-por-ordenador)

---

# TecnologÃ­as principales en visiÃ³n por ordenador

Este documento adapta y amplÃ­a los apuntes originales, estructurÃ¡ndolos en **Markdown** para GitHub. Hemos aÃ±adido tablas comparativas, ejemplos â€œfrikyâ€ (basados en el cine y videojuegos) y un esquema para facilitar el estudio. Â¡Que la Fuerza Friky te acompaÃ±e! ğŸ¬ğŸ‘¾

---

## 1. TensorFlow

TensorFlow es la plataforma de machine learning mÃ¡s utilizada a nivel mundial (o al menos la mÃ¡s mencionada en foros de StackOverflow durante la Ãºltima dÃ©cada). Desarrollada por Google, ofrece un ecosistema muy completo:

### 1.1 Ecosistema y componentes

| Componente        | DescripciÃ³n                                                                 | Analogia Friky                                 |
|-------------------|------------------------------------------------------------------------------|------------------------------------------------|
| **TensorFlow Core**   | Biblioteca central para diseÃ±ar, entrenar y ejecutar modelos de deep learning. | El â€œReactor Arcâ€ de Iron Man: potencia todo     |
| **TensorFlow Lite**   | VersiÃ³n ligera para dispositivos mÃ³viles y microcontroladores.                 | El â€œBatarangâ€ de Batman: pequeÃ±o pero letal     |
| **TensorFlow.js**     | Para ejecutar y entrenar modelos directamente en el navegador.                | Â¿Recuerdas Skeletor invadiendo Internet?        |
| **TensorFlow Hub**    | Repositorio de modelos pre-entrenados (ResNet, EfficientNet, YOLO, etc.).    | La â€œBiblioteca Jediâ€ con paquetes listos para usar |
| **Keras (integrado)** | API de alto nivel para construir redes, mÃ¡s intuitiva que leer un manual de Inception. | La Capa del Olor de Narciso (fÃ¡cil de poner)  |

#### Resumen rÃ¡pido

- **Ecosistema integral**: Desde el Core hasta TensorFlow Lite/JS.
- **Modelos preentrenados**: ResNet, EfficientNet, MobileNet, YOLO en TF Hub.
- **Despliegue en nube**: IntegraciÃ³n nativa con Google Cloud AI Platform.

### 1.2 Fortalezas en visiÃ³n

- **ColecciÃ³n de modelos**: Disponibles en TF Hub, cubren clasificaciÃ³n, detecciÃ³n de objetos, segmentaciÃ³n, etc.
- **TensorFlow Object Detection API**:  
  - Bibliotecas y ejemplos listos para detectar personas, coches, animales.  
  - Tutoriales y notebooks oficiales que parecen salir de â€œEl laboratorio de Dexterâ€.
- **Eager Execution**: Debugging mÃ¡s interactivo, Â¡como si Jarvis te respondiera al instante!
- **tf.data**:  
  - Pipelines optimizados para cargar, transformar y alimentar imÃ¡genes.  
  - Ventaja: procesamiento paralelo en CPU/GPU, ideal para datasets con millones de imÃ¡genes (piensa en los planos de â€œEl SeÃ±or de los Anillosâ€: toneladas de datos).

### 1.3 Facilidad de desarrollo

- **Keras integrado**:  
  - API de alto nivel con clases `Sequential` y `Model`.  
  - Similar a armar una partida de Lego: encajas bloques de capas y ya funciona.
- **Eager Execution por defecto**:  
  - Similar al â€œModo Diosâ€ en videojuegos: ves los valores de los tensores al vuelo.  
  - Facilita prototipado rÃ¡pido.
- **tf.keras.callbacks**:  
  - Callbacks como EarlyStopping, ModelCheckpoint, TensorBoard (visualizaciÃ³n tipo â€œThe Matrixâ€).  

### 1.4 Escalabilidad y despliegue

- **Entrenamiento distribuido**:  
  - `tf.distribute.Strategy` para mÃºltiples GPUs/TPUs.  
  - â€œRed Eyeshield 21â€ entrenando en varios GPUs a la vez.  
- **TPUs de Google**:  
  - Hardware especializado para operaciones tensÃ³ricas.  
  - Igualito que subirte al HalcÃ³n Milenario para hacer warp speed en tu entrenamiento.
- **Google Cloud Platform (GCP)**:  
  - IntegraciÃ³n nativa con AI Platform, AI Notebooks y Dataflow.  
  - Despliegue tipo â€œTony Starkâ€ con un clic.
  
---

## 2. OpenCV (Open Source Computer Vision Library)

OpenCV existe desde hace mÃ¡s de 20 aÃ±os y es la piedra angular de la visiÃ³n tradicional. Si TensorFlow es el Quijote del deep learning, OpenCV es Sancho Panza en la visiÃ³n clÃ¡sica.

### 2.1 Base y algoritmos clÃ¡sicos

- **Filtrado de imÃ¡genes**:  
  - Filtros espaciales (blur, GaussianBlur, medianBlur), detecciÃ³n de bordes (Canny), etc.  
  - Ejemplo friky: aplicar un filtro de Canny y parecer el â€œOjo del Sauronâ€.
- **Transformaciones geomÃ©tricas**:  
  - Rotaciones, escalados, transformaciones afines y perspectiva (warpPerspective).  
  - Es como cambiar la cÃ¡mara en â€œResident Evilâ€: giras la vista para explorar.
- **CalibraciÃ³n de cÃ¡maras**:  
  - EstimaciÃ³n de parÃ¡metros intrÃ­nsecos y extrÃ­nsecos con tableros de ajedrez.  
  - Piensa en la escena de "Up": alineando mÃºltiples perspectivas para hacer el efecto de profundidad.
- **DetecciÃ³n de bordes y caracterÃ­sticas**:  
  - Harris, Shi-Tomasi (goodFeaturesToTrack), SIFT (si tienes licencia), SURF, ORB.  
  - Ejemplo: detectar esquinas como si fuera el â€œMapa del Trollâ€ en â€œHarry Potterâ€.

### 2.2 IntegraciÃ³n multiplataforma

| Lenguaje     | Plataformas Soportadas                  | Casos de Uso MÃ¡s Comunes                                 |
|--------------|-----------------------------------------|----------------------------------------------------------|
| **C++**      | Windows, Linux, macOS, Android, iOS     | Aplicaciones embebidas en robÃ³tica (ROS), sistemas de cÃ¡maras de seguridad. |
| **Python**   | Windows, Linux, macOS                   | Prototipo rÃ¡pido, scripting en pipelines de visiÃ³n.      |
| **Java/Android** | Android                              | Apps mÃ³viles que usan la cÃ¡mara para escanear cÃ³digos o reconocer objetos. |
| **Java (desktop)** | Windows, Linux, macOS              | Aplicaciones empresariales de visiÃ³n industrial.         |
| **Otros (C#, MATLAB, etc.)** | Mediante wrappers                | Integraciones con entornos acadÃ©micos o empresariales.   |

- **Rendimiento en tiempo real**:  
  - Buenas implementaciones en C++ con optimizaciones SSE/NEON.  
  - Permite procesar streams de vÃ­deo a 30â€“60 FPS sin despeinarse (incluso en Raspberry Pi, el FrodÃ³n de los SBC).

### 2.3 Casos de uso y ejemplos â€œfrikyâ€

- **SLAM (Simultaneous Localization And Mapping)**:  
  - LibrerÃ­a `cv::aruco` para marcadores, `ORB-SLAM2`.  
  - Ejemplo: â€œPac-Manâ€ construyendo el mapa mientras come bolitas.
- **Stereo vision**:  
  - Calcular disparidad con `StereoBM` o `StereoSGBM`.  
  - Ejemplo â€œfrikyâ€: Mida la distancia del Dr. Robotnik con dos â€œojosâ€ como C-3PO.
- **Optical Flow**:  
  - Lucas-Kanade, Farneback.  
  - Ejemplo: seguimiento de la pelota en un partido de â€œFIFAâ€ para analizar la trayectoria.
- **Reconocimiento facial (Eigenfaces/Fisherfaces)**:  
  - Un clÃ¡sico que te hace sentir en una pelÃ­cula de los 90 (â€œMen In Blackâ€).
  
### 2.4 Preprocesamiento para deep learning

- **DetecciÃ³n y correcciÃ³n de iluminaciÃ³n**:  
  - EcualizaciÃ³n de histogramas (CLAHE), correcciÃ³n gamma.  
  - Como los â€œcontrasâ€ en TMNT: ajustan la iluminaciÃ³n para que todo brille.
- **Ajuste de tamaÃ±o y normalizaciÃ³n**:  
  - `cv2.resize`, conversiÃ³n a tensores para TensorFlow/PyTorch.  
  - Â¡CÃ³mo convertir una cÃ¡mara VHS en formato digital HD!
- **SegmentaciÃ³n clÃ¡sica**:  
  - UmbralizaciÃ³n, K-means en espacio de color HSV, Watershed.  
  - Ejemplo: â€œMario Kartâ€ segmentando la pista de carrera del fondo.
  
---

## 3. PyTorch

PyTorch, desarrollado por Facebook (Meta), es el framework â€œhipsterâ€ de los investigadores de deep learning. Si TensorFlow es Tony Stark, PyTorch es Doctor Strange: dinÃ¡mico, flexible y perfecto para experimentos surrealistas.

### 3.1 FilosofÃ­a â€œdefine-by-runâ€

- **Grafos dinÃ¡micos**:  
  - Cada operaciÃ³n se construye en tiempo de ejecuciÃ³n.  
  - Control total en cada iteraciÃ³n, como jugar con â€œThe Legend of Zeldaâ€ y poder girar el mundo a tu antojo.
- **Facilidad de debugging**:  
  - Inspeccionas tensores con `print()` o `pdb.set_trace()` sin complicaciones.  
  -âŸComparaciÃ³n: como usar el â€œModo Diosâ€ en â€œSkyrimâ€ para ver valores internos.

### 3.2 Ecosistema TorchVision

- **Datasets predefinidos**:  
  - `CIFAR10`, `ImageNet`, `COCO`, etc.  
  - Cargas con un par de lÃ­neas:  
    ```python
    from torchvision import datasets, transforms
    transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])
    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    ```
- **Transformaciones optimizadas**:  
  - `transforms.RandomCrop`, `transforms.ColorJitter`, `transforms.Normalize`.  
  - Como un mod de â€œFalloutâ€ que transforma texturas al vuelo.
- **Modelos preentrenados**:  
  - `resnet50`, `densenet121`, `vgg16`, `efficientnet_b0`, Vision Transformers (ViT).  
  - Listos para usar con transferencia de aprendizaje.

### 3.3 TransiciÃ³n a producciÃ³n

- **TorchScript**:  
  - Convierte tu modelo dinÃ¡mico a un grafo estÃ¡tico optimizado.  
  - Canon: â€œConviÃ©rtete a hierro, modelito de AIâ€, al estilo de â€œTransformersâ€.
- **TorchServe**:  
  - Servidor para desplegar modelos como endpoints REST.  
  - Perfecto para montar tu propio Jarvis al estilo Tony Stark en la nube.
- **PyTorch Lightning** (opcional):  
  - Estructura el cÃ³digo para separar entrenamiento, validaciÃ³n y testing.  
  - Si eres fan de â€œThe Avengersâ€, te ayuda a coordinar a todos los hÃ©roes en un solo plan.

---

## 4. Otras tecnologÃ­as relevantes

AdemÃ¡s de los grandes protagonistas, existen muchas librerÃ­as y frameworks que pueden complementar tu proyecto de visiÃ³n por ordenador. A continuaciÃ³n, una lista con sus principales caracterÃ­sticas y ejemplos frikis.

### 4.1 Scikit-image y PIL/Pillow

| Biblioteca       | Enfoque                   | Lenguaje  | Funciones clave                                  | Ejemplo friky                                            |
|------------------|---------------------------|-----------|--------------------------------------------------|----------------------------------------------------------|
| **Scikit-image** | Procesamiento cientÃ­fico  | Python    | SegmentaciÃ³n (Otsu, SLIC), anÃ¡lisis de regiones, mÃ©tricas de calidad | Como el â€œHechizo Patronusâ€ en Harry Potter: detecta lo bueno de lo malo. |
| **PIL/Pillow**   | ManipulaciÃ³n bÃ¡sica de imÃ¡genes | Python | Redimensionar, rotar, recortar, conversiÃ³n de formatos | Como un editor de texto en â€œThe Legend of Zeldaâ€: simple pero esencial. |

- **Scikit-image**:  
  - Ideal para anÃ¡lisis de imÃ¡genes mÃ©dicas o cientÃ­ficas.  
  - Funciones avanzadas como transformada de Hough (detectar lÃ­neas y cÃ­rculos), etiquetas de objetos.
- **PIL/Pillow**:  
  - Sencillo, rÃ¡pido.  
  - Carga/guarda en JPG, PNG, GIF, BMP.  
  - Ãštil para pipelines de preprocesamiento ligero antes de soltar el data en TensorFlow o PyTorch.

### 4.2 YOLO (You Only Look Once)

- **Arquitectura de detecciÃ³n en tiempo real**:  
  - Detecta y clasifica objetos en una sola pasada (versus R-CNN que va de dos en dos).  
  - Como el Flash en The Flash: ve todo en un solo vistazo.
- **Versiones mÃ¡s populares**:  
  - **YOLOv5**: PyTorch, ligero, rÃ¡pido (~45 FPS en GPU moderada).  
  - **YOLOv8**: Ultraligero, mejoras de precisiÃ³n y velocidad.  
  - **YOLOv11** (comunidad): Experimentaciones con detectores mÃ¡s rÃ¡pidos.  
- **Tabla comparativa de YOLO vs R-CNN**:

| CaracterÃ­stica              | YOLOv5                                 | Faster R-CNN                          |
|-----------------------------|----------------------------------------|---------------------------------------|
| Velocidad (FPS)             | â‰ˆ45 FPS en GPU moderada                | â‰ˆ5â€“10 FPS                             |
| PrecisiÃ³n (mAP COCO)        | 45â€“55 (depende de la versiÃ³n)          | 42â€“52                                 |
| Complejidad de entrenamiento| MÃ¡s sencillo, scripts oficiales ligeros| Requiere pasos: region proposals + clasificaciÃ³n |
| Uso en friky-world          | Juegos en tiempo real (detecciÃ³n de enemigos al vuelo) | AnÃ¡lisis forense de vÃ­deo (CSI style) |

### 4.3 MediaPipe

- **Framework de Google para anÃ¡lisis multimedia**:  
  - Preconfigurado para detecciÃ³n de pose humana, reconocimiento facial, seguimiento de manos, segmentaciÃ³n de selfies.  
  - Listo para mÃ³vil (Android/iOS).  
- **Casos de uso friky**:  
  - Realidad aumentada: poner mÃ¡scara de Darth Vader en tu cara.  
  - Seguimiento de manos: simular hechizos de â€œDragon Ballâ€ con tus movimientos.  
  - DetecciÃ³n de pose: recrear la coreografÃ­a de â€œThrillerâ€ de Michael Jackson.

### 4.4 Detectron2

- **Plataforma de investigaciÃ³n de Facebook (Meta)**:  
  - Implementa state-of-the-art en detecciÃ³n y segmentaciÃ³n: Mask R-CNN, RetinaNet, DensePose.  
  - Modular y rÃ¡pido para experimentar con arquitecturas nuevas.  
- **Ejemplo friky**:  
  - Usarlo para segmentar personajes en la escena final de â€œAvengers: Endgameâ€ y analizarlos por separado.

### 4.5 Hugging Face Transformers (visiÃ³n)

- **Origen en NLP, ahora multimodal**:  
  - Modelos como ViT (Vision Transformer), CLIP (visiÃ³n + lenguaje).  
  - Facilita acceso a checkpoints entrenados en grandes datasets (ImageNet, LAION).  
- **Aplicaciones**:  
  - BÃºsqueda de imÃ¡genes semÃ¡ntica (â€œÂ¿DÃ³nde estÃ¡ el HalcÃ³n Milenario?â€).  
  - ClasificaciÃ³n de escenas al estilo â€œCazafantasmasâ€: identifica si hay â€œproto-hombreâ€ en la imagen.
- **IntegraciÃ³n sencilla**:  
  - Con un par de lÃ­neas cargas un ViT y lo aplicas a clasificar tus propias capturas de pantalla de videojuegos.

---

## 5. IntegraciÃ³n y flujos de trabajo tÃ­picos

### 5.1 Pipeline hÃ­brido

La mayorÃ­a de proyectos combinan varias herramientas para aprovechar fortalezas de cada una. A continuaciÃ³n, un **esquema** (mermaid) de un flujo de trabajo tÃ­pico:

```mermaid
flowchart TD
  A[ğŸ“· Captura de video/imÃ¡genes] --> B[âš™ï¸ Preprocesamiento (OpenCV, PIL)]
  B --> C[ğŸ” DetecciÃ³n clÃ¡sica / SegmentaciÃ³n inicial (OpenCV, Scikit-image)]
  C --> D[ğŸ¤– Inferencia Deep Learning (TensorFlow / PyTorch)]
  D --> E[ğŸ”„ Post-procesamiento (OpenCV, custom scripts)]
  E --> F[ğŸš€ Despliegue (API REST, App mÃ³vil, Embedded)]
```

  	A â†’ B:
	Captura de cÃ¡mara en vivo o carga de dataset (OpenCV).
	Ajuste de tamaÃ±o, correcciÃ³n de color, aumento de datos.
	B â†’ C:
	Aplicar filtros, detecciÃ³n de contornos, mÃ¡scaras para aislar regiones de interÃ©s.
	Ejemplo: en â€œGhostbustersâ€, primero aislas la â€œDepredadorâ€ (ecto-plasma) antes de analizarlo con un modelo.
	C â†’ D:
	Entrenamiento o inferencia de un modelo CNN/CNN 3D/Transformer.
	Ejemplo friky: tu modelo detecta al T-800 (Terminator) en un plano retroiluminado.
	D â†’ E:
	Filtrado de falsos positivos, tracking de objetos (DeepSORT).
	Ejemplo: en â€œThe Last of Us Part IIâ€, rastreas al enemigo cazador en plena noche.
	E â†’ F:
	Devolver coordenadas, bounding boxes o mÃ¡scaras.
	Despliegue en un API (TorchServe, TensorFlow Serving) o sube a un dispositivo mÃ³vil (TensorFlow Lite, PyTorch Mobile).



5.2 Desarrollo iterativo: InvestigaciÃ³n â†’ ProducciÃ³n

| Fase                          | Herramientas tÃ­picas                                        | Objetivo                                                          |
|-------------------------------|-------------------------------------------------------------|-------------------------------------------------------------------|
| I. Prototipado                | PyTorch (rÃ¡pido), Jupyter Notebooks, OpenCV                 | Explorar ideas, probar arquitecturas, debugging â€œon the flyâ€      |
| II. Entrenamiento a gran escala | TensorFlow (distribuido en TPUs/GPU), PyTorch con DDP       | Escalar al dataset completo, optimizar hiperparÃ¡metros            |
| III. ValidaciÃ³n y benchmarking | TensorBoard, MLflow, comet.ml                                | Monitorizar mÃ©tricas: accuracy, mAP, IOU, F1-score               |
| IV. ConversiÃ³n de modelo       | TorchScript, ONNX, TensorFlow SavedModel                     | Obtener formato optimizado para producciÃ³n                         |
| V. Despliegue                  | TensorFlow Serving, TorchServe, Flask/FastAPI, Docker, Kubernetes | Servir como microservicio, empaquetar en contenedores             |
| VI. Mantenimiento              | ML Monitoring Tools (Prometheus, Grafana)                    | Vigilar drift, rendimiento en producciÃ³n                           |



	â€¢	Ejemplo friky:
	1.	En Phase I, tu modelo detecta PokÃ©mons en pantallas de Mario.
	2.	En Phase II, entrenas en cientos de horas de gameplay de Twitch.
	3.	En Phase III, comparas mÃ©tricas con v1.
	4.	En Phase IV, conviertes tu modelo para que corra en un smartphone (TensorFlow Lite + GPU delegado).
	5.	En Phase V, lo lanzas como app de AR que detecta PokÃ©mons en la calle.
	6.	En Phase VI, monitoreas la tasa de falsos positivos cuando sale un Charizard nuevos en la Galar Region.

5.3 OptimizaciÃ³n en dispositivos embebidos
	â€¢	TensorFlow Lite:
	â€¢	ConversiÃ³n .tflite, cuantizaciÃ³n (int8, float16), delegados de GPU (Android), Coral Edge TPU.
	â€¢	Ejemplo: tu Raspberry Pi 4 interpretando seÃ±ales de Mario Kart en HD.
	â€¢	PyTorch Mobile:
	â€¢	torch.quantization, conversiÃ³n a TorchScript, arquitectura optimizada.
	â€¢	Ideal para iOS/Android (XCode, Android Studio).
	â€¢	OpenCV compilado para ARM:
	â€¢	Utiliza NEON, V4L2 para captura en tiempo real.
	â€¢	Ejemplo â€œfrikyâ€: DetecciÃ³n de intrusos al estilo â€œSilent Hillâ€ con una cÃ¡mara Pi Zero.

5.4 Cloud computing y despliegue
	â€¢	AWS SageMaker, GCP AI Platform, Azure ML:
	â€¢	Entrena sin preocuparte de la infraestructura (como si el jefe final ya estuviera resuelto).
	â€¢	Paga por instancia solo cuando entrenas (Â¡adiÃ³s a los semÃ¡foros eternos!).
	â€¢	Serverless Inference:
	â€¢	AWS Lambda + AWS SageMaker Endpoint, GCP Cloud Functions + Vertex AI.
	â€¢	EjecuciÃ³n a demanda, escalado automÃ¡tico.
	â€¢	Edge Computing:
	â€¢	Google Coral, NVIDIA Jetson Nano, Intel Movidius.
	â€¢	Ideal para robÃ³tica, drones o vehÃ­culos autÃ³nomos (KITT en un Ford Mustang).

â¸»

ApÃ©ndice: Esquema general de un proyecto de visiÃ³n por ordenador

Para ayudar a memorizar y estudiar, presentamos un esquema con los pasos principales, como si fuera un cheat sheet de videojuegos:

1. DefiniciÃ³n del problema
   â”œâ”€ Tipo de tarea: clasificaciÃ³n, detecciÃ³n, segmentaciÃ³n, tracking
   â”œâ”€ Dataset: tamaÃ±o, formato, etiquetas
   â””â”€ MÃ©tricas: accuracy, mAP, IOU, F1-score

2. RecolecciÃ³n y preprocesamiento de datos
   â”œâ”€ Captura de imÃ¡genes/vÃ­deo (OpenCV, cÃ¡maras)
   â”œâ”€ Limpieza y etiquetado (LabelImg, CVAT)
   â”œâ”€ Aumento de datos (rotaciones, flip, cambios de brillo)
   â””â”€ DivisiÃ³n en entrenamiento/validaciÃ³n/test

3. SelecciÃ³n de arquitectura
   â”œâ”€ Modelos clÃ¡sicos: SVM, HOG+SVM, Haar Cascades (OpenCV)
   â”œâ”€ Modelos CNN: ResNet, MobileNet, EfficientNet
   â”œâ”€ Modelos de detecciÃ³n: YOLO, SSD, Faster R-CNN
   â””â”€ Modelos de segmentaciÃ³n: U-Net, Mask R-CNN

4. Entrenamiento
   â”œâ”€ Framework: PyTorch (define-by-run) o TensorFlow (estÃ¡tico/dinÃ¡mico)
   â”œâ”€ ConfiguraciÃ³n: tasas de aprendizaje, optimizadores (Adam, SGD)
   â”œâ”€ Callbacks/Checkpoints (TensorBoard, ModelCheckpoint)
   â””â”€ ValidaciÃ³n temprana (EarlyStopping)

5. EvaluaciÃ³n y ajuste
   â”œâ”€ MÃ©tricas clave: matriz de confusiÃ³n, curvas ROC, PR
   â”œâ”€ Ajuste de hiperparÃ¡metros (Grid Search, Bayesian Search)
   â”œâ”€ Data Augmentation adicional si hay overfitting
   â””â”€ Pruebas en dataset real (robustez en escenarios â€œno perfectosâ€)

6. ConversiÃ³n y optimizaciÃ³n
   â”œâ”€ PyTorch â†’ TorchScript â†’ Podar y cuantizar
   â”œâ”€ TensorFlow â†’ SavedModel â†’ .tflite + cuantizaciÃ³n
   â”œâ”€ ONNX como puente entre frameworks
   â””â”€ Benchmarking en hardware objetivo

7. Despliegue
   â”œâ”€ Microservicios: TorchServe, TensorFlow Serving, FastAPI
   â”œâ”€ Contenedores: Docker + Kubernetes (yak, minikube)
   â”œâ”€ Edge: TensorFlow Lite, PyTorch Mobile, OpenCV compilado
   â””â”€ Monitoreo y mantenimiento (Prometheus, Grafana)

8. Mantenimiento y escalado
   â”œâ”€ Re-entrenamiento con datos nuevos (drift detection)
   â”œâ”€ Monitoreo de mÃ©tricas en producciÃ³n
   â”œâ”€ Actualizaciones periÃ³dicas del modelo
   â””â”€ DocumentaciÃ³n y versiÃ³n de cÃ³digo (GitHub, DVC)